{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62755e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Colab 适配版 - 单元格 1: 安装库\n",
    "# =======================================================================\n",
    "print(\"Installing core libraries: transformers, datasets, accelerate\")\n",
    "!pip install -q -U transformers datasets accelerate\n",
    "print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2137137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Colab 适配版 - 单元格 2: 登录 Hugging Face Hub\n",
    "# =======================================================================\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata  # <-- 使用 Colab 的密钥管理工具\n",
    "\n",
    "try:\n",
    "    # 在 Colab 左侧边栏的“密钥”图标中，添加名为 HUGGINGFACE_TOKEN 的密钥\n",
    "    hf_token = userdata.get(\"HUGGINGFACE_TOKEN\")\n",
    "    print(\"Hugging Face token found in Colab Secrets. Logging in...\")\n",
    "    login(token=hf_token)\n",
    "    print(\"Login successful.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        \"Could not log in to Hugging Face. Please ensure HUGGINGFACE_TOKEN is set correctly in Colab Secrets.\"\n",
    "    )\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c575e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Colab 适配版 - 单元格 3: 配置参数\n",
    "# =======================================================================\n",
    "class TrainingConfig:\n",
    "    MODEL_ID = \"distilgpt2\"\n",
    "\n",
    "    # --- 请根据您上传文件的方式，选择并修改下面的路径 ---\n",
    "    # 方式 A: 如果您是直接上传到会话存储\n",
    "    # DATA_FILE_PATH = \"/content/training_data_for_agent.jsonl\"\n",
    "\n",
    "    # 方式 B (推荐): 如果您挂载了 Google Drive\n",
    "    DATA_FILE_PATH = \"/content/drive/MyDrive/Colab_Data/training_data_for_agent.jsonl\"\n",
    "\n",
    "    # Colab 的可写目录是 /content/\n",
    "    OUTPUT_DIR = \"/content/distilgpt2_full_finetuned\"\n",
    "\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  - Model: {TrainingConfig.MODEL_ID}\")\n",
    "print(f\"  - Data file: {TrainingConfig.DATA_FILE_PATH}\")\n",
    "print(f\"  - Output directory: {TrainingConfig.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d392582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Colab 适配版 - 单元格 4: 简化的训练逻辑 (与 Kaggle 版相同)\n",
    "# =======================================================================\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "# --- 数据加载和处理部分 ---\n",
    "print(f\"Loading dataset from {TrainingConfig.DATA_FILE_PATH}...\")\n",
    "dataset = load_dataset(\"json\", data_files=TrainingConfig.DATA_FILE_PATH, split=\"train\")\n",
    "print(f\"Dataset loaded with {len(dataset)} records.\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TrainingConfig.MODEL_ID)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    texts = []\n",
    "    for prompt, tool_calls in zip(examples[\"prompt\"], examples[\"tool_calls\"]):\n",
    "        completion_obj = {\"tool_calls\": tool_calls}\n",
    "        completion_str = json.dumps(completion_obj, ensure_ascii=False)\n",
    "        text = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n{completion_str}<end_of_turn>\"\n",
    "        texts.append(text)\n",
    "    tokenized_output = tokenizer(\n",
    "        texts, padding=\"longest\", truncation=True, max_length=512\n",
    "    )\n",
    "    tokenized_output[\"labels\"] = [x[:] for x in tokenized_output[\"input_ids\"]]\n",
    "    return tokenized_output\n",
    "\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=dataset.column_names\n",
    ")\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# --- 极简的模型加载 ---\n",
    "print(\"Loading model for full finetuning...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    TrainingConfig.MODEL_ID,\n",
    "    device_map=\"auto\",  # 在 Colab 中，auto 会自动选择可用的 GPU\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(\"Model prepared for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b971af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 使用标准的训练参数 ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=TrainingConfig.OUTPUT_DIR,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    dataloader_num_workers=0,\n",
    "    fp16=True,  # Colab 的 GPU 通常都支持 fp16\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# --- 开始训练 ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training finished successfully! The environment is working.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
